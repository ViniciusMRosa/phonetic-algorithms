{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes Iniciais dos Algoritimos Tratamento de Nomes\n",
    "\n",
    "Bibliotecas utilizadas\n",
    "\n",
    "- NTLK \n",
    "- Soundex \n",
    "    - Instalar no Python as bibliotecas soundex e silpa_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRSA \n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "from suds.client import Client\n",
    "\n",
    "url = \"http://mundoincrivel.com.br/fonetica.asmx?wsdl\"\n",
    "\n",
    "cliente = Client(url)\n",
    "\n",
    "resultado = cliente.service.Transformar('THEREZA')\n",
    "print resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import pandas  as pd\n",
    "from soundex import Soundex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação dos algoritimos RSLP e Snowball (Português) - NLTK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chavesoundex = Soundex()\n",
    "stemmerRSLP = nltk.stem.RSLPStemmer()\n",
    "stemmersnow = SnowballStemmer(\"portuguese\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação de uma Base de Nomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nomes = pd.read_csv('nomes_unicos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ABDALA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ABDIAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ABEILARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ABEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ABELA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      NOME\n",
       "0   1    ABDALA\n",
       "1   2    ABDIAS\n",
       "2   3  ABEILARD\n",
       "3   4      ABEL\n",
       "4   5     ABELA"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomes.NOME = nomes.NOME.str.decode('cp1252')\n",
    "nomes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de Colunas Novas com o resultado de cada algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#l = len(nomes[\"NOME\"])\n",
    "\n",
    "#nomes[\"RSLP\"] = \"\"\n",
    "#nomes[\"SNOW\"] = \"\"\n",
    "#nomes[\"CHAVESOUNDEX\"] = \"\"\n",
    "\n",
    "\n",
    "#for i in range(l):\n",
    "#    nomes[\"RSLP\"] [i] = stemmerRSLP.stem(nomes[\"NOME\"][i]).upper().strip()\n",
    "#    nomes[\"SNOW\"] [i] = stemmersnow.stem(nomes[\"NOME\"] [i]).upper().strip()\n",
    "#    nomes[\"CHAVESOUNDEX\"] [i] = chavesoundex.soundex(nomes[\"NOME\"] [i]).upper().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação do BuscaBR  e algoritimo do Roberto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class fonetica(object):\n",
    "        \n",
    "    def chavefoneticaBR(self,palavra,retiravogal):\n",
    "        \n",
    "        chave = palavra.encode('ASCII','ignore').upper()\n",
    "        \n",
    "        # Substituir as vogais acentuadas \n",
    "                \n",
    "        chave = chave.replace(\"Á\", \"A\");\n",
    "\n",
    "        chave = chave.replace(\"À\", \"A\");\n",
    "\n",
    "        chave = chave.replace(\"Ã\", \"A\");\n",
    "\n",
    "        chave = chave.replace(\"Ê\", \"E\");\n",
    "\n",
    "        chave = chave.replace(\"É\", \"E\");\n",
    "\n",
    "        chave = chave.replace(\"Í\", \"I\");\n",
    "\n",
    "        chave = chave.replace(\"Ó\", \"O\");\n",
    "\n",
    "        chave = chave.replace(\"Õ\", \"O\");\n",
    "\n",
    "        chave = chave.replace(\"Ú\", \"U\");\n",
    "\n",
    "        \n",
    "        # substituir Y por I\n",
    "        \n",
    "        chave = chave.replace('Y','I')\n",
    "        \n",
    "        # Substituimos BR por B\n",
    "\n",
    "        chave = chave.replace('BR', 'B')\n",
    "\n",
    "        chave = chave.replace('BL', 'B')\n",
    "\n",
    "        # Substituimos PH por F\n",
    "\n",
    "        chave = chave.replace('PH', 'F')\n",
    "\n",
    "        # Substituimos GR, MG, NG, RG por G\n",
    "\n",
    "        chave = chave.replace('MG', 'G')\n",
    "\n",
    "        chave = chave.replace('NG', 'G')\n",
    "\n",
    "        chave = chave.replace('RG', 'G')\n",
    "\n",
    "        # Substituimos GE, GI, RJ, MJ, NJ por J\n",
    "\n",
    "        chave = chave.replace('GE', 'J')\n",
    "\n",
    "        chave = chave.replace('GI', 'J')\n",
    "\n",
    "        chave = chave.replace('RJ', 'J')\n",
    "\n",
    "        chave = chave.replace('MJ', 'J')\n",
    "\n",
    "        chave = chave.replace('NJ', 'J')\n",
    "\n",
    "        chave = chave.replace('GR', 'G')\n",
    "\n",
    "        chave = chave.replace('GL', 'G')\n",
    "\n",
    "        # Substituimos CE, CI e CH por S\n",
    "\n",
    "        chave = chave.replace('CE', 'S')\n",
    "\n",
    "        chave = chave.replace('CI', 'S')\n",
    "\n",
    "        chave = chave.replace('CH', 'S')\n",
    "\n",
    "        # Substituimos CT por T\n",
    "\n",
    "        chave = chave.replace('CT', 'T')\n",
    "\n",
    "        chave = chave.replace('CS', 'S')\n",
    "\n",
    "        # Substituimos Q, CA, CO, CU, C por K\n",
    "\n",
    "        chave = chave.replace('Q', 'K')\n",
    "\n",
    "        chave = chave.replace('CA', 'K')\n",
    "\n",
    "        chave = chave.replace('CO', 'K')\n",
    "\n",
    "        chave = chave.replace('CU', 'K')\n",
    "\n",
    "        chave = chave.replace('CK', 'K')\n",
    "\n",
    "        chave = chave.replace('C', 'K')\n",
    "\n",
    "        # Substituimos LH por L\n",
    "\n",
    "        chave = chave.replace('LH', 'L')\n",
    "\n",
    "        chave = chave.replace('RM', 'SM')\n",
    "\n",
    "        # Substituimos N, RM, GM, MD, SM e Terminação AO por M\n",
    "\n",
    "        chave = chave.replace('N', 'M')\n",
    "\n",
    "        chave = chave.replace('GM', 'M')\n",
    "\n",
    "        chave = chave.replace('MD', 'M')\n",
    "\n",
    "        # Substituimos NH por N\n",
    "\n",
    "        chave = chave.replace('NH', 'N')\n",
    "\n",
    "        # Substituimos PR por P\n",
    "\n",
    "        chave = chave.replace('PR', 'P')\n",
    "\n",
    "        # Substituimos Ç, X, TS, C, Z, RS por S\n",
    "\n",
    "        chave = chave.replace('X', 'S')\n",
    "\n",
    "        chave = chave.replace('TS', 'S')\n",
    "\n",
    "        chave = chave.replace('C', 'S')\n",
    "\n",
    "        chave = chave.replace('Ç', 'S')\n",
    "\n",
    "        chave = chave.replace('Z', 'S')\n",
    "\n",
    "        chave = chave.replace('RS', 'S')\n",
    "\n",
    "        # Substituimos LT, TR, CT, RT, ST por T\n",
    "\n",
    "        chave = chave.replace('TR', 'T')\n",
    "\n",
    "        chave = chave.replace('TL', 'T')\n",
    "\n",
    "        chave = chave.replace('LT', 'T')\n",
    "\n",
    "        chave = chave.replace('RT', 'T')\n",
    "\n",
    "        chave = chave.replace('ST', 'T')\n",
    "\n",
    "        # Substituimos W por V\n",
    "\n",
    "        chave = chave.replace('W', 'V')\n",
    "        \n",
    "        #  Eliminamos as terminações S, Z, R, R, M, N, AO e L;\n",
    "\n",
    "        tam = len(chave) - 1\n",
    "\n",
    "        if (tam > -1):\n",
    "            \n",
    "            if (chave[tam]=='S' or chave[tam]=='Z' or chave[tam]=='R' or chave[tam]=='M' or chave[tam]=='N' or chave[tam]=='L'):\n",
    "                \n",
    "                chave = chave[0:tam]\n",
    "                \n",
    "        tam = len(chave) - 2\n",
    "\n",
    "        if (tam > -1):\n",
    "\n",
    "            if (chave[tam] == 'A' and chave[tam + 1] == 'O'):\n",
    "                \n",
    "                chave = chave[0:tam]\n",
    "\n",
    "        # Substituimos L por R;\n",
    "\n",
    "        chave = chave.replace('L', 'R')\n",
    "        \n",
    "        # Substituir todas as vogais \n",
    "        \n",
    "        if (retiravogal):\n",
    "            \n",
    "            chave = chave.replace('A', '')\n",
    "            chave = chave.replace('E', '')\n",
    "            chave = chave.replace('I', '')\n",
    "            chave = chave.replace('O', '')\n",
    "            chave = chave.replace('U', '')\n",
    "        \n",
    "        # Substituir o H\n",
    "        \n",
    "        chave = chave.replace('H', '')\n",
    "       \n",
    "        if len(chave) > 0 : \n",
    "            chave = self.retirarrepetidas(chave)\n",
    "        \n",
    "        return chave\n",
    "\n",
    "    def retirarrepetidas(self,texto): \n",
    "        \n",
    "        # Eliminamos todas as letras em duplicidade;\n",
    "        \n",
    "        frasesaida = ''\n",
    "        \n",
    "        frasesaida = texto[0]\n",
    "        \n",
    "        \n",
    "        for i in range(len(texto)):\n",
    "            \n",
    "            if (frasesaida[len(frasesaida) - 1] != texto[i]) or (texto[i].isdigit()):\n",
    "                \n",
    "                frasesaida += texto[i]\n",
    "                \n",
    "                \n",
    "        return frasesaida        \n",
    "    \n",
    "    # Chave Fonetica do Roberto \n",
    "    \n",
    "    \n",
    "    def chavefoneticaRoberto(self,texto):    \n",
    "        \n",
    "        from unicodedata import normalize\n",
    "        from nltk import word_tokenize\n",
    "        \n",
    "        consoantes = ['B','C','D','F','G','H','J','K','L','M','N','P','Q','R','S','T','V','W','X','Y','Z']\n",
    "        vogais = ['A','E','I','O','U']            \n",
    "        \n",
    "        def tratarpalavras(palavra):\n",
    "            \n",
    "            palavra = self.retirarrepetidas(palavra).upper()\n",
    "            \n",
    "            x = len(palavra)\n",
    "           \n",
    "            palavra = tratarconsoante(palavra)\n",
    "                      \n",
    "            if (palavra[0] == 'H'):\n",
    "                y=1\n",
    "            else:\n",
    "                y=0\n",
    "            \n",
    "            quantidade = x-y\n",
    "            \n",
    "            palavra = self.retirarrepetidas(palavra)\n",
    "            \n",
    "            tratada = tratarvogal(palavra)\n",
    "            \n",
    "            if len(palavra) != len(tratada): \n",
    "                \n",
    "                encontro = True\n",
    "            else: \n",
    "                encontro = False\n",
    "                \n",
    "            tratada = tratarquantidade(tratada,quantidade,encontro)\n",
    "            \n",
    "            return tratada\n",
    "        \n",
    "        def tratarconsoante(tratar):\n",
    "            \n",
    "            tratar = tratar.replace('PH','F')\n",
    "            tratar = tratar.replace('CH','X')\n",
    "            tratar = tratar.replace('SH','X')\n",
    "            tratar = tratar.replace('LH','I')\n",
    "            tratar = tratar.replace('NH','I')\n",
    "            tratar = tratar.replace('K','C')\n",
    "            tratar = tratar.replace('Q','C')\n",
    "            tratar = tratar.replace('V','U')\n",
    "            tratar = tratar.replace('W','U')\n",
    "            tratar = tratar.replace('Y','I')\n",
    "            tratar = tratar.replace('Z','S')\n",
    "            \n",
    "            \n",
    "            \n",
    "            tam = len(tratar)\n",
    "            \n",
    "            tratada = ''\n",
    "                                    \n",
    "            for i in range(tam): \n",
    "                \n",
    "                if (i+1 < tam) and ((tratar[i]=='C') or (tratar[i]=='G')): \n",
    "                \n",
    "                    if ((tratar[i]=='C') and (tratar[i+1] in ['E','I','Y'])):\n",
    "\n",
    "                        tratada += 'S'\n",
    "\n",
    "                    elif ((tratar[i]=='G') and (tratar[i+1] in ['E','I','Y'])):           \n",
    "\n",
    "                        tratada += 'J'\n",
    "                        \n",
    "                    else  :\n",
    "                    \n",
    "                        tratada += tratar[i]    \n",
    "\n",
    "                elif (i+1 < tam) and (i-1 >= 0 ) and ((tratar[i]=='H') or (tratar[i]=='E')):\n",
    "                                        \n",
    "                    if ((tratar[i]=='H') and (tratar[i-1] in consoantes)  and (tratar[i+1] in consoantes)):           \n",
    "                        \n",
    "                        tratada += ''\n",
    "                        \n",
    "                    elif ((tratar[i]=='E') and not((tratar[i-1] == 'I') or (tratar[i+1] == 'U')) ) :     \n",
    "                        \n",
    "                        tratada += 'I'\n",
    "                    \n",
    "                    else:\n",
    "                                           \n",
    "                        tratada += tratar[i]\n",
    "                        \n",
    "                elif (tratar[i]=='Q'):\n",
    "                                          \n",
    "                    tratada += 'C'\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    tratada += tratar[i]\n",
    "             \n",
    "            return tratada\n",
    "        \n",
    "        def tratarvogal(tratar):\n",
    "\n",
    "            tam = len(tratar)\n",
    "\n",
    "            tratada = ''\n",
    "\n",
    "            seq = ''\n",
    "            invogal = False\n",
    "\n",
    "            for i in range(tam): \n",
    "\n",
    "\n",
    "                if (tratar[i] in vogais):\n",
    "\n",
    "                    if invogal:\n",
    "\n",
    "                        seq += tratar[i]\n",
    "\n",
    "                    else: \n",
    "\n",
    "                        seq = tratar[i]\n",
    "                        invogal = True\n",
    "\n",
    "                elif invogal:\n",
    "\n",
    "                    invogal = False\n",
    "\n",
    "                    if len(seq) > 2:\n",
    "\n",
    "                        seq = seq[-2:] \n",
    "\n",
    "                    tratada = tratada + seq + tratar[i]\n",
    "\n",
    "                    seq = ''\n",
    "\n",
    "                else:\n",
    "\n",
    "                    tratada += tratar[i]  \n",
    "                    \n",
    "            if invogal:\n",
    "\n",
    "                if len(seq) > 2:\n",
    "\n",
    "                    seq = seq[-2:] \n",
    "\n",
    "                tratada = tratada + seq \n",
    "\n",
    "            return tratada\n",
    "\n",
    "        def tratarquantidade(tratar,quantidade,inencontro):\n",
    "            \n",
    "            #print tratar, quantidade, inencontro\n",
    "            \n",
    "            tratada = ''\n",
    "            \n",
    "            if quantidade <=4 and not inencontro:\n",
    "                \n",
    "                stop = False\n",
    "                \n",
    "                for i in range(len(tratar)):\n",
    "                    \n",
    "                    \n",
    "                    if tratar[i] in vogais and not stop:\n",
    "                        \n",
    "                        stop = True                        \n",
    "                    \n",
    "                    else:\n",
    "                        \n",
    "                        tratada += tratar[i]\n",
    "                        \n",
    "            elif quantidade == 5 and not inencontro:\n",
    "                \n",
    "                if tratar[0] in consoantes and tratar[1] in consoantes:\n",
    "                    \n",
    "                    stop = False\n",
    "                \n",
    "                    for i in range(len(tratar)):\n",
    "\n",
    "\n",
    "                        if tratar[-i-1] in vogais and not stop:\n",
    "\n",
    "                            stop = True                        \n",
    "\n",
    "                        else:\n",
    "\n",
    "                            tratada = tratar[-i-1] + tratada\n",
    "                else:\n",
    "                                       \n",
    "                    tratada = tratar\n",
    "                            \n",
    "            elif quantidade == 6 and not inencontro:\n",
    "                \n",
    "                if tratar[len(tratar)-1] in consoantes:\n",
    "                    \n",
    "                    stop = False\n",
    "                \n",
    "                    for i in range(len(tratar)):\n",
    "\n",
    "                        if tratar[i] in vogais and not stop:\n",
    "\n",
    "                            stop = True                        \n",
    "\n",
    "                        else:\n",
    "\n",
    "                            tratada += tratar[i]\n",
    "                            \n",
    "                else:\n",
    "                    \n",
    "                    stop = False\n",
    "                \n",
    "                    for i in range(len(tratar)):\n",
    "\n",
    "\n",
    "                        if tratar[-i-1] in vogais and not stop:\n",
    "\n",
    "                            stop = True                        \n",
    "\n",
    "                        else:\n",
    "\n",
    "                            tratada = tratar[-i-1] + tratada\n",
    "\n",
    "            elif quantidade >= 6:\n",
    "                \n",
    "                stop = False\n",
    "                \n",
    "                for i in range(len(tratar)):\n",
    "                    \n",
    "                    if tratar[-i-1] in vogais and not stop:\n",
    "                        \n",
    "                        stop = True                        \n",
    "\n",
    "                    else:\n",
    "\n",
    "                        tratada = tratar[-i-1] + tratada\n",
    "            else: \n",
    "                \n",
    "                tratada = tratar\n",
    "                            \n",
    "            return tratada        \n",
    "\n",
    "        texto = normalize('NFKD', texto).encode('ASCII','ignore').upper()\n",
    "        \n",
    "        word_tokens = word_tokenize(texto)\n",
    "        \n",
    "        stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "        \n",
    "        filtro = [word.lower() for word in word_tokens if word.lower() not in stopwords]\n",
    "        \n",
    "        chave = \"\"\n",
    "        \n",
    "        for p in filtro:\n",
    "            \n",
    "            chave = chave + tratarpalavras(p) + \" \"\n",
    "        \n",
    "        return chave\n",
    "        \n",
    "    def metaphoneBR(self,texto): \n",
    "        \n",
    "        from unicodedata import normalize\n",
    "        \n",
    "        from nltk import word_tokenize\n",
    "\n",
    "        vogais = ['A','E','I','O','U']  \n",
    "        \n",
    "        saidas_validas = ['D','T','F','J','K','V','B','M']\n",
    "\n",
    "        def tratarpalavras(tratar):\n",
    "            \n",
    "            tratar = tratar.upper()\n",
    "            \n",
    "            tam = len(tratar)\n",
    "            \n",
    "            consoante = ''\n",
    "            \n",
    "            # Substitui o Y pelo seu correspondente vocálico \n",
    "            \n",
    "            tratar = tratar.replace('Y','I')\n",
    "            \n",
    "            for l in range(tam):\n",
    "                \n",
    "                letra = tratar[l]\n",
    "                \n",
    "                if letra == 'C':\n",
    "                    \n",
    "                    if (l > 0) and tratar[l-1] in ('S','X'): \n",
    "                        \n",
    "                        consoante = consoante \n",
    "\n",
    "                    elif (l < tam -1): \n",
    "                        \n",
    "                        if tratar[l+1] == 'H':\n",
    "                            \n",
    "                            consoante += 'X'                      \n",
    "                        \n",
    "                        elif  tratar[l+1] in ['E','I']:\n",
    "                            \n",
    "                            consoante += 'S'  \n",
    "                            \n",
    "                        elif  tratar[l+1] in ['A','O','U','R']:\n",
    "                            \n",
    "                            consoante += 'K'  \n",
    "                     \n",
    "                elif letra == 'G':\n",
    "                    \n",
    "                    if (l < tam -1) and tratar[l+1] == 'E':\n",
    "                        \n",
    "                        consoante += 'J'  \n",
    "                        \n",
    "                    else: \n",
    "                            \n",
    "                        consoante += 'G'\n",
    "                            \n",
    "                elif letra == 'P':\n",
    "                    \n",
    "                    if (l < tam -1) and tratar[l+1] == 'H':\n",
    "                            \n",
    "                        consoante += 'F'  \n",
    "                        \n",
    "                    else: \n",
    "                            \n",
    "                        consoante += 'P'\n",
    "\n",
    "                elif letra == 'L':\n",
    "                    \n",
    "                    if (l < tam -1) and tratar[l+1] == 'H':\n",
    "                            \n",
    "                        consoante += '1'  \n",
    "                        \n",
    "                    else: \n",
    "                            \n",
    "                        consoante += 'L'\n",
    "\n",
    "                elif letra == 'R':\n",
    "                    \n",
    "                    if (l < tam -1) and tratar[l+1] == 'R':\n",
    "                            \n",
    "                        consoante += '2'  \n",
    "\n",
    "                    elif (l == tam -1) or (l ==1):\n",
    "                            \n",
    "                        consoante += '2'  \n",
    "                        \n",
    "                    else: \n",
    "                            \n",
    "                        consoante += 'R'\n",
    "\n",
    "                elif letra == 'N':\n",
    "                    \n",
    "                    if (l < tam -1) and tratar[l+1] == 'H':\n",
    "                            \n",
    "                        consoante += '3'  \n",
    "\n",
    "                    elif (l == tam -1) :\n",
    "                            \n",
    "                        consoante += 'M'  \n",
    "                        \n",
    "                    elif (l>0) and (tratar[l-1] != 'N'): \n",
    "                            \n",
    "                        consoante += 'N'\n",
    "                        \n",
    "                    elif (l==0): \n",
    "                            \n",
    "                        consoante += 'N'    \n",
    "                        \n",
    "                elif letra == 'Q':\n",
    "                    \n",
    "                    consoante += 'K'  \n",
    "\n",
    "                # Se não estiver no final e for cercado por vogais, tem som de Z    \n",
    "                \n",
    "                elif letra == 'S':\n",
    "                    \n",
    "                    if (l < tam-1) and (l > 0) and (tratar[l+1] in vogais) and (tratar[l-1] in vogais):\n",
    "                            \n",
    "                        consoante += 'Z'  \n",
    "                    \n",
    "                    elif (l < tam -1) and (l > 0) and (tratar[l+1] == 'S'):\n",
    "                        \n",
    "                        consoante = consoante\n",
    "\n",
    "                    elif (l < tam -1) and (l > 0) and (tratar[l+1] == 'H'):\n",
    "                        \n",
    "                        consoante += 'X'\n",
    "                    \n",
    "                    elif (l < tam -1) and (tratar[l+1] == 'C'):\n",
    "                        \n",
    "                        if (l < tam -2) and tratar[l+2] in ['E','I']:\n",
    "                            \n",
    "                            consoante += 'S'\n",
    "\n",
    "                        elif (l < tam -2) and tratar[l+2] in ['A','O','U']:\n",
    "                            \n",
    "                            consoante += 'SK'\n",
    "\n",
    "                        elif (l < tam -2) and tratar[l+2] == 'H':\n",
    "                            \n",
    "                            consoante += 'X'\n",
    "                        \n",
    "                        else: \n",
    "                            \n",
    "                            consoante += 'S'\n",
    "                            \n",
    "                    else: \n",
    "                            \n",
    "                        consoante += 'S'\n",
    "                        \n",
    "                elif letra == 'Z':\n",
    "                    \n",
    "                    if (l == tam-1):\n",
    "                            \n",
    "                        consoante += 'S'  \n",
    "                    \n",
    "                    else: \n",
    "                            \n",
    "                        consoante += 'Z'\n",
    "\n",
    "                elif letra == 'X':\n",
    "                    \n",
    "                    if (l == tam-1):\n",
    "                            \n",
    "                        consoante += 'X'  \n",
    "                    \n",
    "                    elif (l > 0) and (tratar[l-1] == 'E'):\n",
    "                        \n",
    "                        if (l < tam-2) and (tratar[l+1] in vogais):\n",
    "                                                    \n",
    "                            if ((l-1) == 0):\n",
    "\n",
    "                                consoante += 'Z' \n",
    "\n",
    "                            elif (l < tam-1) and tratar[l+1] in ('E','I'):\n",
    "\n",
    "                                consoante += 'X'\n",
    "\n",
    "                            else:\n",
    "\n",
    "                                consoante += 'KS'\n",
    "                                \n",
    "                        elif (l < tam-1) and (tratar[l+1]in ['C','P','T']):\n",
    "                            \n",
    "                            consoante += 'S'\n",
    "                        \n",
    "                        else:\n",
    "                                                          \n",
    "                            consoante += 'KS'\n",
    "\n",
    "                    elif (l > 0) and tratar[l-1] in vogais:\n",
    "                                                          \n",
    "                        if (l > 1) and (tratar[l-2] in ['C','K','G','L','R','X'] or tratar[l-2] in vogais):\n",
    "                            \n",
    "                             consoante += 'X'\n",
    "                         \n",
    "                        else:\n",
    "                                                          \n",
    "                            consoante += 'KS'                                          \n",
    "                                                          \n",
    "                    else: \n",
    "                        \n",
    "                        consoante += 'X'\n",
    "                        \n",
    "                elif letra == 'W':\n",
    "                    \n",
    "                    consoante += 'V'\n",
    "                \n",
    "                elif letra in vogais:\n",
    "                    \n",
    "                    if l == 0:\n",
    "                        \n",
    "                        consoante += letra\n",
    "                    \n",
    "                    else: \n",
    "                        \n",
    "                        consoante = consoante\n",
    "                \n",
    "                elif letra in ['Y','H']:\n",
    "                    \n",
    "                    consoante = consoante\n",
    "                \n",
    "                elif letra in saidas_validas:\n",
    "                    \n",
    "                    consoante += letra\n",
    "            \n",
    "            tratada = consoante\n",
    " \n",
    "            return tratada\n",
    "        \n",
    "                \n",
    "        texto = texto.upper()\n",
    "        \n",
    "        texto = texto.replace(U'\\x87','SS')\n",
    "        \n",
    "        texto = normalize('NFKD', texto).encode('ASCII','ignore').upper()\n",
    "        \n",
    "        word_tokens = word_tokenize(texto)\n",
    "        \n",
    "        stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "        \n",
    "        filtro = [word.lower() for word in word_tokens if word.lower() not in stopwords]\n",
    "        \n",
    "        chave = \"\"\n",
    "        \n",
    "        for p in word_tokens:\n",
    "            \n",
    "            chave = chave + tratarpalavras(p) + \" \"\n",
    "        \n",
    "        return chave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARMAS BROIS ASINALADS CAROS \n",
      "AS A2MS E OS BRS ASNLDS E OS K2RS \n",
      "AS ASMAS E OS BARES ASIMARADOS E OS KRO\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chave = fonetica()\n",
    "texto = 'AS ARMAS E OS BARÕES ASSINALADOS E OS CARROS'\n",
    "print chave.chavefoneticaRoberto(texto.decode('utf-8'))\n",
    "print chave.metaphoneBR(texto.decode('utf-8'))\n",
    "print chave.chavefoneticaBR(texto.decode('utf-8'),False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de três novas colunas:\n",
    "\n",
    "1 - Chave BuscaBR com retirada das vogais (http://www.linhadecodigo.com.br/artigo/2237/implementando-algoritmo-buscabr.aspx)\n",
    "\n",
    "2 - Chave BuscaBR sem retirada das vogais (http://www.linhadecodigo.com.br/artigo/2237/implementando-algoritmo-buscabr.aspx)\n",
    "\n",
    "3 - Chave Fonetica do Roberto (Lider Seguradora - V0)\n",
    "\n",
    "4 - Chave Fonética Metaphone PTBR (http://informatica.varzeapaulista.sp.gov.br/metaphone/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vinicius Martins\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Vinicius Martins\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Vinicius Martins\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Vinicius Martins\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Vinicius Martins\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Vinicius Martins\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Vinicius Martins\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "l = len(nomes[\"NOME\"])\n",
    "\n",
    "nomes[\"BUSCABRV\"] = \"\"\n",
    "nomes[\"BUSCABR\"] = \"\"\n",
    "nomes[\"LIDER\"] = \"\"\n",
    "nomes[\"METAPHONEBR\"] = \"\"\n",
    "nomes[\"RSLP\"] = \"\"\n",
    "nomes[\"SNOW\"] = \"\"\n",
    "nomes[\"CHAVESOUNDEX\"] = \"\"\n",
    "\n",
    "for i in range(l):\n",
    "    nomes[\"RSLP\"] [i] = stemmerRSLP.stem(nomes[\"NOME\"][i]).upper().strip()\n",
    "    nomes[\"SNOW\"] [i] = stemmersnow.stem(nomes[\"NOME\"] [i]).upper().strip()\n",
    "    nomes[\"CHAVESOUNDEX\"] [i] = chavesoundex.soundex(nomes[\"NOME\"] [i]).upper().strip()\n",
    "    nomes[\"BUSCABRV\"] [i] = chave.chavefoneticaBR(nomes[\"NOME\"][i],True).upper().strip()\n",
    "    nomes[\"BUSCABR\"] [i] = chave.chavefoneticaBR(nomes[\"NOME\"][i],False).upper().strip()\n",
    "    try:\n",
    "        nomes[\"LIDER\"] [i] = cliente.service.Transformar(normalize('NFKD', nomes[\"NOME\"][i]).encode('ASCII','ignore').upper()).upper().strip()\n",
    "    except:\n",
    "        nomes[\"LIDER\"] [i] = 'Erro ao buscar'\n",
    "        print('Erro ao buscar ' + normalize('NFKD', nomes[\"NOME\"][i]).encode('ASCII','ignore').upper())\n",
    "    nomes[\"METAPHONEBR\"] [i] = chave.metaphoneBR(nomes[\"NOME\"][i]).upper().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nomes.to_csv(path_or_buf='nomes_com_chaves_ws.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nomes_com_chave = pd.read_csv('nomes_com_chaves_ws.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abraa\n"
     ]
    }
   ],
   "source": [
    "var = stemmersnow.stem('ABRAAO')\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando por *UON *\n",
      "Buscando por *UIT *\n",
      "Buscando por *CLUIS *\n",
      "Buscando por *LAS *\n",
      "Buscando por *LAIRT *\n",
      "Buscando por *UILNGTON *\n",
      "Buscando por *TRSA *\n",
      "Buscando por *TRSNIA *\n",
      "Buscando por *TIAG *\n",
      "Buscando por *TLMA *\n",
      "Buscando por *SLIO *\n",
      "Buscando por *RUT *\n",
      "Buscando por *RSMRI *\n",
      "Buscando por *RAIMNDO *\n",
      "Buscando por *RFAIL *\n",
      "Buscando por *FLPI *\n",
      "Buscando por *BRAO *\n",
      "Buscando por *DNSTI *\n",
      "Buscando por *JSCA *\n"
     ]
    }
   ],
   "source": [
    "busca = [\"IVONE\",\"IVETE\",\"CLOVIS\",\"LACI\",\"LAERTE\",\"WELINGTON\",\"TERESA\",\"TERESINHA\",\"TIAGO\",\"THELMA\",\"SILVIO\",\"RUTE\",\"ROSEMERI\",\"RAIMUNDO\",\"RAFAEL\",\"FELIPE\",\"ABRAO\",\"DONISETE\",\"GESSICA\"]\n",
    "b = pd.DataFrame() \n",
    "records = []         \n",
    "for palavra in busca:        \n",
    "    chaveFonetica = chave.metaphoneBR(palavra)\n",
    "    resultadoMPBR = nomes_com_chave[nomes_com_chave['METAPHONEBR']==chaveFonetica].NOME\n",
    "    \n",
    "    chaveFonetica =  cliente.service.Transformar(palavra)\n",
    "    print('Buscando por *' + chaveFonetica + '*')\n",
    "    resultadoLider = nomes_com_chave[nomes_com_chave['LIDER']==chaveFonetica.strip()].NOME  \n",
    "    \n",
    "    chaveFonetica = stemmerRSLP.stem(palavra)\n",
    "    resultadoRSLP = nomes_com_chave[nomes_com_chave['RSLP']==chaveFonetica].NOME  \n",
    "    \n",
    "    chaveFonetica = chavesoundex.soundex(palavra)\n",
    "    resultadoSOUND = nomes_com_chave[nomes_com_chave['CHAVESOUNDEX']==chaveFonetica].NOME  \n",
    "    \n",
    "    chaveFonetica = chave.chavefoneticaBR(unicode(palavra),False)\n",
    "    resultadoBSBRP = nomes_com_chave[nomes_com_chave['BUSCABR']==chaveFonetica].NOME  \n",
    "    \n",
    "    chaveFonetica = chave.chavefoneticaBR(unicode(palavra),True)\n",
    "    resultadoBSBRV = nomes_com_chave[nomes_com_chave['BUSCABRV']==chaveFonetica].NOME  \n",
    "    \n",
    "    chaveFonetica = stemmersnow.stem(palavra)\n",
    "    resultadoSNOW = nomes_com_chave[nomes_com_chave['SNOW']==chaveFonetica].NOME      \n",
    "\n",
    "    data = {\"BUSCA\":palavra, \\\n",
    "            \"RSLP\":list(resultadoRSLP.iloc[:].values),\\\n",
    "            \"SNOW\":list(resultadoSNOW.iloc[:].values),\\\n",
    "            \"CHAVESOUNDEX\":list(resultadoSOUND.iloc[:].values),\\\n",
    "            \"BUSCABRV\":list(resultadoBSBRV.iloc[:].values),\\\n",
    "            \"BUSCABR\":list(resultadoBSBRP.iloc[:].values),\\\n",
    "            \"METAPHONEBR\":list(resultadoMPBR.iloc[:].values),\\\n",
    "            \"LIDER\":list(resultadoLider.iloc[:].values)} \n",
    "    records.append(data)\n",
    "df = pd.DataFrame(records,columns=[\"BUSCA\",\"RSLP\",\"SNOW\",\"CHAVESOUNDEX\",\"BUSCABRV\",\"BUSCABR\",\"METAPHONEBR\", \"LIDER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(path_or_buf='resultado_buscas2.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vinicius Martins\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao tentar buscar a chave do nome DILCElinha 892\n",
      "Erro ao tentar buscar a chave do nome JEZIELlinha 1885\n",
      "Erro ao tentar buscar a chave do nome ZULMIRAlinha 3286\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "nomes_com_chave = pd.read_csv(filepath_or_buffer ='nomes_com_chaves.csv',encoding='utf-8')\n",
    "l = len(nomes_com_chave[\"NOME\"])\n",
    "for i in range(l):\n",
    "    \n",
    "    texto = normalize('NFKD', unicode(nomes_com_chave[\"NOME\"][i])).encode('ASCII','ignore').upper()\n",
    "    #print('Verificando ' + unicode(nomes_com_chave[\"NOME\"][i]) + ' ['+texto+']')\n",
    "    try:\n",
    "        nomes_com_chave[\"LIDER\"] [i] =  cliente.service.Transformar(texto)\n",
    "    except:\n",
    "        print('Erro ao tentar buscar a chave do nome ' + texto + 'linha ' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nomes_com_chave.to_csv(path_or_buf='resultado_buscas_ws.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nomes_com_chave = pd.read_csv('nomes_com_chaves_ws.csv')\n",
    "def busca_nome(palavra):     \n",
    "    chaveFonetica = chave.metaphoneBR(palavra)\n",
    "    resultadoMPBR = nomes_com_chave[nomes_com_chave['METAPHONEBR']==chaveFonetica].NOME\n",
    "    \n",
    "    chaveFonetica =  cliente.service.Transformar(palavra)\n",
    "    resultadoLider = nomes_com_chave[nomes_com_chave['LIDER']==chaveFonetica.strip()].NOME  \n",
    "    \n",
    "    chaveFonetica = stemmerRSLP.stem(palavra)\n",
    "    resultadoRSLP = nomes_com_chave[nomes_com_chave['RSLP']==chaveFonetica.upper()].NOME  \n",
    "    \n",
    "    chaveFonetica = chavesoundex.soundex(palavra)\n",
    "    resultadoSOUND = nomes_com_chave[nomes_com_chave['CHAVESOUNDEX']==chaveFonetica].NOME  \n",
    "    \n",
    "    chaveFonetica = chave.chavefoneticaBR(unicode(palavra),False)\n",
    "    resultadoBSBRP = nomes_com_chave[nomes_com_chave['BUSCABR']==chaveFonetica].NOME  \n",
    "    \n",
    "    chaveFonetica = chave.chavefoneticaBR(unicode(palavra),True)\n",
    "    resultadoBSBRV = nomes_com_chave[nomes_com_chave['BUSCABRV']==chaveFonetica].NOME  \n",
    "    \n",
    "    chaveFonetica = stemmersnow.stem(palavra)\n",
    "    resultadoSNOW = nomes_com_chave[nomes_com_chave['SNOW']==chaveFonetica.upper()].NOME      \n",
    "\n",
    "    data = {\"RSLP\":{\"NOMESENCONTRADOS\":list(resultadoRSLP.iloc[:].values)},\\\n",
    "            \"SNOW\":{\"NOMESENCONTRADOS\":list(resultadoSNOW.iloc[:].values)},\\\n",
    "            \"CHAVESOUNDEX\":{\"NOMESENCONTRADOS\":list(resultadoSOUND.iloc[:].values)},\\\n",
    "            \"BUSCABRV\":{\"NOMESENCONTRADOS\":list(resultadoBSBRV.iloc[:].values)},\\\n",
    "            \"BUSCABR\":{\"NOMESENCONTRADOS\":list(resultadoBSBRP.iloc[:].values)},\\\n",
    "            \"METAPHONEBR\":{\"NOMESENCONTRADOS\":list(resultadoMPBR.iloc[:].values)},\\\n",
    "            \"LIDER\":{\"NOMESENCONTRADOS\":list(resultadoLider.iloc[:].values)}\n",
    "            } \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vinicius Martins\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:11: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "C:\\Users\\Vinicius Martins\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:17: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RSLP', 40, 13, 64, '=', 0.7547169811320755, 0.38461538461538464)\n",
      "('SNOWBALL', 41, 16, 63, '=', 0.7192982456140351, 0.3942307692307692)\n",
      "('SOUNDEX', 83, 195, 21, '=', 0.29856115107913667, 0.7980769230769231)\n",
      "('BUSCABRV', 96, 1621, 8, '=', 0.05591147350029121, 0.9230769230769231)\n",
      "('BUSCABR', 76, 8, 28, '=', 0.9047619047619048, 0.7307692307692307)\n",
      "('METAPHONEBR', 73, 121, 31, '=', 0.37628865979381443, 0.7019230769230769)\n",
      "('LIDER', 82, 102, 22, '=', 0.44565217391304346, 0.7884615384615384)\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, '')\n",
    "\n",
    "records = []\n",
    "\n",
    "def contar_ocorrencias(esperado,nomesEncontrados):\n",
    "    acertos = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for index,item in enumerate(esperado):\n",
    "        if item in nomesEncontrados:\n",
    "            acertos += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    #calcular falsos positivos\n",
    "    for index,item in enumerate(nomesEncontrados):\n",
    "        if item not in esperado:\n",
    "            fp += 1\n",
    "    #print('Esperado: ', esperado , ' Encontrados: ' , nomesEncontrados , ' Acertos: ' , str(acertos), 'FP',fp,'FN',fn )     \n",
    "    return acertos,fp,fn\n",
    "  \n",
    "sumacertos = [0,0,0,0,0,0,0]\n",
    "sumfp = [0,0,0,0,0,0,0]\n",
    "sumfn = [0,0,0,0,0,0,0]\n",
    "\n",
    "buscasdf = pd.read_csv(filepath_or_buffer='buscas_milton.csv', sep=';',encoding='utf-8')\n",
    "for index,row in buscasdf.iterrows():\n",
    "    busca = row['BUSCA']\n",
    "    data = busca_nome(busca)\n",
    "    resultado = row['Retorno Esperado'].split(',')\n",
    "    \n",
    "    #Dados de cada algoritmo\n",
    "    acertos = [0,0,0,0,0,0,0]\n",
    "    fp = [0,0,0,0,0,0,0]\n",
    "    fn = [0,0,0,0,0,0,0]\n",
    "    \n",
    "    #RSLP\n",
    "    nomesEncontrados = data['RSLP']['NOMESENCONTRADOS']\n",
    "    acertos[0],fp[0],fn[0] = contar_ocorrencias(resultado,nomesEncontrados)\n",
    "    sumacertos[0] += acertos[0]\n",
    "    sumfp[0] += fp[0]\n",
    "    sumfn[0] += fn[0]\n",
    "    \n",
    "    #SNOWBALL\n",
    "    nomesEncontrados = data['SNOW']['NOMESENCONTRADOS']\n",
    "    acertos[1],fp[1],fn[1] = contar_ocorrencias(resultado,nomesEncontrados)\n",
    "    sumacertos[1] += acertos[1]\n",
    "    sumfp[1] += fp[1]\n",
    "    sumfn[1] += fn[1]\n",
    "    \n",
    "    #SOUNDEX\n",
    "    nomesEncontrados = data['CHAVESOUNDEX']['NOMESENCONTRADOS']\n",
    "    acertos[2],fp[2],fn[2] = contar_ocorrencias(resultado,nomesEncontrados)\n",
    "    sumacertos[2] += acertos[2]\n",
    "    sumfp[2] += fp[2]\n",
    "    sumfn[2] += fn[2]\n",
    "        \n",
    "    #BUSCABRV\n",
    "    nomesEncontrados = data['BUSCABRV']['NOMESENCONTRADOS']\n",
    "    acertos[3],fp[3],fn[3] = contar_ocorrencias(resultado,nomesEncontrados)\n",
    "    sumacertos[3] += acertos[3]\n",
    "    sumfp[3] += fp[3]\n",
    "    sumfn[3] += fn[3]\n",
    "        \n",
    "    #BUSCABR\n",
    "    nomesEncontrados = data['BUSCABR']['NOMESENCONTRADOS']\n",
    "    acertos[4],fp[4],fn[4] = contar_ocorrencias(resultado,nomesEncontrados)\n",
    "    sumacertos[4] += acertos[4]\n",
    "    sumfp[4] += fp[4]\n",
    "    sumfn[4] += fn[4]\n",
    "        \n",
    "    #METAPHONE\n",
    "    nomesEncontrados = data['METAPHONEBR']['NOMESENCONTRADOS']\n",
    "    acertos[5],fp[5],fn[5] = contar_ocorrencias(resultado,nomesEncontrados)\n",
    "    sumacertos[5] += acertos[5]\n",
    "    sumfp[5] += fp[5]\n",
    "    sumfn[5] += fn[5]\n",
    "        \n",
    "    #LIDER\n",
    "    nomesEncontrados = data['LIDER']['NOMESENCONTRADOS']\n",
    "    acertos[6],fp[6],fn[6] = contar_ocorrencias(resultado,nomesEncontrados)\n",
    "    sumacertos[6] += acertos[6]\n",
    "    sumfp[6] += fp[6]\n",
    "    sumfn[6] += fn[6]\n",
    "        \n",
    "    linha ={\"BUSCA\":busca,\"Resultado Esperado\": row['Retorno Esperado'],\\\n",
    "            'RSLP': data['RSLP']['NOMESENCONTRADOS'],\"ACRSLP\": str( acertos[0]),\"FPRSLP\": str(fp[0]),\"FNRSLP\":str(fn[0]),\\\n",
    "            'SNOW': data['SNOW']['NOMESENCONTRADOS'],\"ACSNOW\": str( acertos[1]),\"FPSNOW\": str(fp[1]),\"FNSNOW\":str(fn[1]),\\\n",
    "            'CHAVESOUNDEX': data['CHAVESOUNDEX']['NOMESENCONTRADOS'],\"ACCHAVESOUNDEX\": str( acertos[2]),\"FPCHAVESOUNDEX\": str(fp[2]),\"FNCHAVESOUNDEX\":str(fn[2]),\\\n",
    "            'BUSCABRV': data['BUSCABRV']['NOMESENCONTRADOS'],\"ACBUSCABRV\": str( acertos[3]),\"FPBUSCABRV\": str(fp[3]),\"FNBUSCABRV\":str(fn[3]),\\\n",
    "            'BUSCABR': data['BUSCABR']['NOMESENCONTRADOS'],\"ACBUSCABR\": str( acertos[4]),\"FPBUSCABR\": str(fp[4]),\"FNBUSCABR\":str(fn[4]),\\\n",
    "            'METAPHONEBR': data['METAPHONEBR']['NOMESENCONTRADOS'],\"ACMETAPHONEBR\": str(acertos[5]),\"FPMETAPHONEBR\": str(fp[5]),\"FNMETAPHONEBR\":str(fn[5]),\\\n",
    "            'LIDER': data['LIDER']['NOMESENCONTRADOS'],\"ACLIDER\": str( acertos[6]),\"FPLIDER\": str(fp[6]),\"FNLIDER\":str(fn[6]) }\n",
    "    \n",
    "    records.append(linha)\n",
    "    \n",
    "    \n",
    "#Gerar linha com sumarizacao    \n",
    "linha ={\"BUSCA\":\"\",\"Resultado Esperado\": \"\",\\\n",
    "        'RSLP': \"\",\"ACRSLP\": str( sumacertos[0]),\"FPRSLP\": str(sumfp[0]),\"FNRSLP\":str(sumfn[0]),\\\n",
    "        'SNOW': \"\",\"ACSNOW\": str( sumacertos[1]),\"FPSNOW\": str(sumfp[1]),\"FNSNOW\":str(sumfn[1]),\\\n",
    "        'CHAVESOUNDEX': \"\",\"ACCHAVESOUNDEX\": str( sumacertos[2]),\"FPCHAVESOUNDEX\": str(sumfp[2]),\"FNCHAVESOUNDEX\":str(sumfn[2]),\\\n",
    "        'BUSCABRV':\"\",\"ACBUSCABRV\": str( sumacertos[3]),\"FPBUSCABRV\": str(sumfp[3]),\"FNBUSCABRV\":str(sumfn[3]),\\\n",
    "        'BUSCABR': \"\",\"ACBUSCABR\": str( sumacertos[4]),\"FPBUSCABR\": str(sumfp[4]),\"FNBUSCABR\":str(sumfn[4]),\\\n",
    "        'METAPHONEBR': \"\",\"ACMETAPHONEBR\": str( sumacertos[5]),\"FPMETAPHONEBR\": str(sumfp[5]),\"FNMETAPHONEBR\":str(sumfn[5]),\\\n",
    "        'LIDER': \"\",\"ACLIDER\": str( sumacertos[6]),\"FPLIDER\": str(sumfp[6]),\"FNLIDER\":str(sumfn[6]) }\n",
    "\n",
    "records.append(linha)\n",
    " \n",
    "    \n",
    "#Gerar metrica F1\n",
    "\n",
    "# Os nomes das colunas devem seguir o mesmo padrao por causa da serialização em arquivo do pandas\n",
    "linha = {\"BUSCA\":\"Algoritmo\",\"Resultado Esperado\":\"Precision\",\"RSLP\":\"Recall\",\"ACRSLP\":\"F1\"}\n",
    "records.append(linha)\n",
    "\n",
    "altoritmos =[\"RSLP\",\"SNOWBALL\",\"SOUNDEX\",\"BUSCABRV\",\"BUSCABR\",\"METAPHONEBR\",\"LIDER\"]\n",
    "\n",
    "for x in range(0, 7): \n",
    "    \n",
    "    precision = float(sumacertos[x])/(sumacertos[x]+sumfp[x])\n",
    "    recall = float(sumacertos[x])/(sumacertos[x]+sumfn[x])\n",
    "    f1 = float(2*(precision*recall)/(precision+recall))\n",
    "    \n",
    "    linha = {\"BUSCA\":altoritmos[x],\"Resultado Esperado\":'{percent:.2%}'.format(percent=precision).replace('.',','),\n",
    "             \"RSLP\":'{percent:.2%}'.format(percent=recall).replace('.',','),\"ACRSLP\":'{percent:.2%}'.format(percent=f1).replace('.',',')}\n",
    "    records.append(linha)\n",
    "\n",
    "df = pd.DataFrame(records,columns=[\"BUSCA\",\"Resultado Esperado\",\\\n",
    "                                   \"RSLP\",\"ACRSLP\",\"FPRSLP\",\"FNRSLP\",\\\n",
    "                                   \"SNOW\",\"ACSNOW\",\"FPSNOW\",\"FNSNOW\",\n",
    "                                   \"CHAVESOUNDEX\",\"ACCHAVESOUNDEX\",\"FPCHAVESOUNDEX\",\"FNCHAVESOUNDEX\",\n",
    "                                   \"BUSCABRV\",\"ACBUSCABRV\",\"FPBUSCABRV\",\"FNBUSCABRV\",\n",
    "                                   \"BUSCABR\",\"ACBUSCABR\",\"FPBUSCABR\",\"FNBUSCABR\",\n",
    "                                   \"METAPHONEBR\",\"ACMETAPHONEBR\",\"FPMETAPHONEBR\",\"FNMETAPHONEBR\",\n",
    "                                   \"LIDER\",\"ACLIDER\",\"FPLIDER\",\"FNLIDER\"])    \n",
    "df.to_csv(path_or_buf='testes_automaticos_milton.csv',index=False,encoding='utf-8',sep=\";\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Portuguese_Brazil.1252'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
