{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes Iniciais dos Algoritimos de Chave Fonética\n",
    "\n",
    "Bibliotecas utilizadas\n",
    "\n",
    "- NTLK \n",
    "- Bibliotecas com implemetações próprias:\n",
    "    - Algoritimo da seguradora\n",
    "    - Buscabr \n",
    "    - MetaphoneBR\n",
    "- Soundex \n",
    "    - Instalar no Python as bibliotecas soundex e silpa_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from foneticaBR import foneticaBR\n",
    "from buscabr import buscaBR\n",
    "from soundex import Soundex\n",
    "from metaphoneBR import metaphoneBR\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import pandas  as pd\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chaveRoberto = foneticaBR()\n",
    "chavebr = buscaBR()\n",
    "chavemeta = metaphoneBR()\n",
    "chavesoundex = Soundex()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação dos algoritimos RSLP e Snowball (Português) - NLTK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chavesoundex = Soundex()\n",
    "stemmerRSLP = nltk.stem.RSLPStemmer()\n",
    "stemmersnow = SnowballStemmer(\"portuguese\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação de uma Base de Nomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nomes = pd.read_csv('nomes_unicos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿\"ID\"</th>\n",
       "      <th>NOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ABDALA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ABDIAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ABEILARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ABEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ABELA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ﻿\"ID\"      NOME\n",
       "0      1    ABDALA\n",
       "1      2    ABDIAS\n",
       "2      3  ABEILARD\n",
       "3      4      ABEL\n",
       "4      5     ABELA"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nomes.NOME = nomes.NOME.str.decode('cp1252')\n",
    "nomes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADAO\n",
      "AD\n",
      "D\n",
      "AD\n",
      "A3\n",
      "adã\n",
      "adã\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "foneticaBR.py:388: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  filtro = [word.lower() for word in word_tokens if word.lower() not in stopwords]\n",
      "metaphoneBR.py:297: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  filtro = [word.lower() for word in word_tokens if word.lower() not in stopwords]\n"
     ]
    }
   ],
   "source": [
    "texto = nomes[\"NOME\"][39]\n",
    "print chaveRoberto.chavefonetica(texto)\n",
    "print chavebr.chaveBR(texto,False)\n",
    "print chavebr.chaveBR(texto,True)\n",
    "print chavemeta.chaveMetaphoneBR(texto)\n",
    "print chavesoundex.soundex(texto.decode('utf-8'))\n",
    "print stemmerRSLP.stem(texto.decode('utf-8'))\n",
    "print stemmersnow.stem(texto.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação de Colunas Novas com o resultado de cada algoritmo\n",
    "\n",
    "1 - RSLP - Sttemer Português (http://www.inf.ufrgs.br/~viviane/rslp/ e http://www.nltk.org/_modules/nltk/stem/rslp.html)\n",
    "\n",
    "2 - SNOWBALL - Sttemer (http://www.nltk.org/howto/stem.html)\n",
    "\n",
    "3 - Chave BuscaBR com retirada das vogais (http://www.linhadecodigo.com.br/artigo/2237/implementando-algoritmo-buscabr.aspx)\n",
    "\n",
    "4 - Chave BuscaBR sem retirada das vogais (http://www.linhadecodigo.com.br/artigo/2237/implementando-algoritmo-buscabr.aspx)\n",
    "\n",
    "5 - Chave Fonetica do Roberto (Lider Seguradora - V0)\n",
    "\n",
    "6 - Chave Fonética Metaphone PTBR (http://informatica.varzeapaulista.sp.gov.br/metaphone/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milton\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Milton\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Milton\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Milton\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Milton\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Milton\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Milton\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "l = len(nomes[\"NOME\"])\n",
    "\n",
    "nomes[\"BUSCABR_SEM_VOGAL\"] = \"\"\n",
    "nomes[\"BUSCABR\"] = \"\"\n",
    "nomes[\"ROBERTO\"] = \"\"\n",
    "nomes[\"METAPHONEBR\"] = \"\"\n",
    "nomes[\"RSLP\"] = \"\"\n",
    "nomes[\"SNOW\"] = \"\"\n",
    "nomes[\"CHAVESOUNDEX\"] = \"\"\n",
    "\n",
    "for i in range(l):\n",
    "    try: \n",
    "        nome = nomes[\"NOME\"][i].upper().strip()\n",
    "        nomes[\"RSLP\"] [i] = stemmerRSLP.stem(nome.decode('utf-8')).upper()\n",
    "        nomes[\"SNOW\"] [i] = stemmersnow.stem(nome.decode('utf-8')).upper()\n",
    "        nomes[\"CHAVESOUNDEX\"] [i] = chavesoundex.soundex(nome.decode('utf-8'))\n",
    "        nomes[\"BUSCABR_SEM_VOGAL\"] [i] =  chavebr.chaveBR(nome,True)\n",
    "        nomes[\"BUSCABR\"] [i] =  chavebr.chaveBR(nome,False)\n",
    "        nomes[\"ROBERTO\"] [i] = chaveRoberto.chavefonetica(nome)\n",
    "        nomes[\"METAPHONEBR\"] [i] = chavemeta.chaveMetaphoneBR(nome)\n",
    "    except:\n",
    "        print nomes[\"NOME\"][i]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nomes.iloc[:,1:9].to_csv(path_or_buf='nomes_com_chaves_ws.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nomes_com_chave = pd.read_csv('nomes_com_chaves_ws.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOME</th>\n",
       "      <th>BUSCABR_SEM_VOGAL</th>\n",
       "      <th>BUSCABR</th>\n",
       "      <th>ROBERTO</th>\n",
       "      <th>METAPHONEBR</th>\n",
       "      <th>RSLP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>CHAVESOUNDEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABDALA</td>\n",
       "      <td>BDR</td>\n",
       "      <td>ABDARA</td>\n",
       "      <td>ABDAL</td>\n",
       "      <td>ABDL</td>\n",
       "      <td>ABDAL</td>\n",
       "      <td>ABDAL</td>\n",
       "      <td>A134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABDIAS</td>\n",
       "      <td>BD</td>\n",
       "      <td>ABDIA</td>\n",
       "      <td>BDIAS</td>\n",
       "      <td>ABDS</td>\n",
       "      <td>ABD</td>\n",
       "      <td>ABDI</td>\n",
       "      <td>A132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABEILARD</td>\n",
       "      <td>BRD</td>\n",
       "      <td>ABEIRARD</td>\n",
       "      <td>BLARD</td>\n",
       "      <td>ABLRD</td>\n",
       "      <td>ABEILARD</td>\n",
       "      <td>ABEILARD</td>\n",
       "      <td>A1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABEL</td>\n",
       "      <td>B</td>\n",
       "      <td>ABE</td>\n",
       "      <td>ABL</td>\n",
       "      <td>ABL</td>\n",
       "      <td>ABEL</td>\n",
       "      <td>ABEL</td>\n",
       "      <td>A14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABELA</td>\n",
       "      <td>BR</td>\n",
       "      <td>ABERA</td>\n",
       "      <td>ABL</td>\n",
       "      <td>ABL</td>\n",
       "      <td>ABEL</td>\n",
       "      <td>ABEL</td>\n",
       "      <td>A14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABELARD</td>\n",
       "      <td>BRD</td>\n",
       "      <td>ABERARD</td>\n",
       "      <td>BLARD</td>\n",
       "      <td>ABLRD</td>\n",
       "      <td>ABELARD</td>\n",
       "      <td>ABELARD</td>\n",
       "      <td>A1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABELINO</td>\n",
       "      <td>BRM</td>\n",
       "      <td>ABERIMO</td>\n",
       "      <td>BLNO</td>\n",
       "      <td>ABLN</td>\n",
       "      <td>ABELIN</td>\n",
       "      <td>ABELIN</td>\n",
       "      <td>A145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABIA</td>\n",
       "      <td>B</td>\n",
       "      <td>ABIA</td>\n",
       "      <td>ABIA</td>\n",
       "      <td>AB</td>\n",
       "      <td>ABI</td>\n",
       "      <td>ABI</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABIANOR</td>\n",
       "      <td>BM</td>\n",
       "      <td>ABIAMO</td>\n",
       "      <td>BIANOR</td>\n",
       "      <td>ABN2</td>\n",
       "      <td>ABIAN</td>\n",
       "      <td>ABIANOR</td>\n",
       "      <td>A156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ABIDIAS</td>\n",
       "      <td>BD</td>\n",
       "      <td>ABIDIA</td>\n",
       "      <td>BDIAS</td>\n",
       "      <td>ABDS</td>\n",
       "      <td>ABID</td>\n",
       "      <td>ABID</td>\n",
       "      <td>A132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ABIGAIL</td>\n",
       "      <td>BG</td>\n",
       "      <td>ABIGAI</td>\n",
       "      <td>BGAIL</td>\n",
       "      <td>ABGL</td>\n",
       "      <td>ABIGAIL</td>\n",
       "      <td>ABIGAIL</td>\n",
       "      <td>A124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ABILIO</td>\n",
       "      <td>BR</td>\n",
       "      <td>ABIRIO</td>\n",
       "      <td>BLIO</td>\n",
       "      <td>ABL</td>\n",
       "      <td>ABILI</td>\n",
       "      <td>ABILI</td>\n",
       "      <td>A14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ABINER</td>\n",
       "      <td>BM</td>\n",
       "      <td>ABIME</td>\n",
       "      <td>ABNR</td>\n",
       "      <td>ABN2</td>\n",
       "      <td>ABIN</td>\n",
       "      <td>ABIN</td>\n",
       "      <td>A156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ABIZAI</td>\n",
       "      <td>BS</td>\n",
       "      <td>ABISAI</td>\n",
       "      <td>BSAI</td>\n",
       "      <td>ABZ</td>\n",
       "      <td>ABIZ</td>\n",
       "      <td>ABIZA</td>\n",
       "      <td>A12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ABNE</td>\n",
       "      <td>BM</td>\n",
       "      <td>ABME</td>\n",
       "      <td>ABN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>ABNE</td>\n",
       "      <td>A15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ABNER</td>\n",
       "      <td>BM</td>\n",
       "      <td>ABME</td>\n",
       "      <td>ABNR</td>\n",
       "      <td>ABN2</td>\n",
       "      <td>ABN</td>\n",
       "      <td>ABNER</td>\n",
       "      <td>A156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ABRAAO</td>\n",
       "      <td>B</td>\n",
       "      <td>ABA</td>\n",
       "      <td>ABRAO</td>\n",
       "      <td>ABR</td>\n",
       "      <td>ABRAA</td>\n",
       "      <td>ABRAA</td>\n",
       "      <td>A16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ABRAO</td>\n",
       "      <td>B</td>\n",
       "      <td>AB</td>\n",
       "      <td>ABRAO</td>\n",
       "      <td>ABR</td>\n",
       "      <td>ABRA</td>\n",
       "      <td>ABRA</td>\n",
       "      <td>A16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACACIO</td>\n",
       "      <td>KS</td>\n",
       "      <td>AKSO</td>\n",
       "      <td>CSIO</td>\n",
       "      <td>AKS</td>\n",
       "      <td>ACACI</td>\n",
       "      <td>ACACI</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ACEDINA</td>\n",
       "      <td>SDM</td>\n",
       "      <td>ASDIMA</td>\n",
       "      <td>SDNA</td>\n",
       "      <td>ASDN</td>\n",
       "      <td>ACEDIN</td>\n",
       "      <td>ACEDIN</td>\n",
       "      <td>A235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        NOME BUSCABR_SEM_VOGAL   BUSCABR ROBERTO METAPHONEBR      RSLP  \\\n",
       "0     ABDALA               BDR    ABDARA   ABDAL        ABDL     ABDAL   \n",
       "1     ABDIAS                BD     ABDIA   BDIAS        ABDS       ABD   \n",
       "2   ABEILARD               BRD  ABEIRARD   BLARD       ABLRD  ABEILARD   \n",
       "3       ABEL                 B       ABE     ABL         ABL      ABEL   \n",
       "4      ABELA                BR     ABERA     ABL         ABL      ABEL   \n",
       "5    ABELARD               BRD   ABERARD   BLARD       ABLRD   ABELARD   \n",
       "6    ABELINO               BRM   ABERIMO    BLNO        ABLN    ABELIN   \n",
       "7       ABIA                 B      ABIA    ABIA          AB       ABI   \n",
       "8    ABIANOR                BM    ABIAMO  BIANOR        ABN2     ABIAN   \n",
       "9    ABIDIAS                BD    ABIDIA   BDIAS        ABDS      ABID   \n",
       "10   ABIGAIL                BG    ABIGAI   BGAIL        ABGL   ABIGAIL   \n",
       "11    ABILIO                BR    ABIRIO    BLIO         ABL     ABILI   \n",
       "12    ABINER                BM     ABIME    ABNR        ABN2      ABIN   \n",
       "13    ABIZAI                BS    ABISAI    BSAI         ABZ      ABIZ   \n",
       "14      ABNE                BM      ABME     ABN         ABN       ABN   \n",
       "15     ABNER                BM      ABME    ABNR        ABN2       ABN   \n",
       "16    ABRAAO                 B       ABA   ABRAO         ABR     ABRAA   \n",
       "17     ABRAO                 B        AB   ABRAO         ABR      ABRA   \n",
       "18    ACACIO                KS      AKSO    CSIO         AKS     ACACI   \n",
       "19   ACEDINA               SDM    ASDIMA    SDNA        ASDN    ACEDIN   \n",
       "\n",
       "        SNOW CHAVESOUNDEX  \n",
       "0      ABDAL         A134  \n",
       "1       ABDI         A132  \n",
       "2   ABEILARD        A1463  \n",
       "3       ABEL          A14  \n",
       "4       ABEL          A14  \n",
       "5    ABELARD        A1463  \n",
       "6     ABELIN         A145  \n",
       "7        ABI           A1  \n",
       "8    ABIANOR         A156  \n",
       "9       ABID         A132  \n",
       "10   ABIGAIL         A124  \n",
       "11     ABILI          A14  \n",
       "12      ABIN         A156  \n",
       "13     ABIZA          A12  \n",
       "14      ABNE          A15  \n",
       "15     ABNER         A156  \n",
       "16     ABRAA          A16  \n",
       "17      ABRA          A16  \n",
       "18     ACACI           A2  \n",
       "19    ACEDIN         A235  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nomes_com_chave.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração de Arquivo com o Resultado da Busca de Todos os Nomes da Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milton\\Anaconda\\lib\\site-packages\\pandas\\core\\ops.py:683: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  result = lib.scalar_compare(x, y, op)\n"
     ]
    }
   ],
   "source": [
    "busca = nomes[\"NOME\"]\n",
    "b = pd.DataFrame() \n",
    "records = []         \n",
    "for palavra in busca:\n",
    "    \n",
    "    chaveFonetica = chavemeta.chaveMetaphoneBR(palavra)\n",
    "    resultadoMPBR =nomes_com_chave[nomes_com_chave['METAPHONEBR']==chaveFonetica].NOME\n",
    "    \n",
    "    chaveFonetica =  chaveRoberto.chavefonetica(palavra)\n",
    "    resultadoLider = nomes_com_chave[nomes_com_chave['ROBERTO']==chaveFonetica.strip()].NOME  \n",
    "    \n",
    "    chaveFonetica = stemmerRSLP.stem(palavra.decode('utf-8')).upper()\n",
    "    resultadoRSLP = nomes_com_chave[nomes_com_chave['RSLP']==chaveFonetica].NOME  \n",
    "    \n",
    "    chaveFonetica = chavesoundex.soundex(palavra.decode('utf-8'))\n",
    "    resultadoSOUND = nomes_com_chave[nomes_com_chave['CHAVESOUNDEX']==chaveFonetica].NOME  \n",
    "    \n",
    "    chaveFonetica = chavebr.chaveBR(palavra,False)\n",
    "    resultadoBSBRP = nomes_com_chave[nomes_com_chave['BUSCABR']==chaveFonetica].NOME  \n",
    "    \n",
    "    chaveFonetica = chavebr.chaveBR(palavra,True)\n",
    "    resultadoBSBRV = nomes_com_chave[nomes_com_chave['BUSCABR_SEM_VOGAL']==chaveFonetica].NOME  \n",
    "    \n",
    "    chaveFonetica = stemmersnow.stem(palavra.decode('utf-8')).upper()\n",
    "    resultadoSNOW = nomes_com_chave[nomes_com_chave['SNOW']==chaveFonetica].NOME      \n",
    "\n",
    "    data = {\"BUSCA\":palavra, \\\n",
    "            \"RSLP\":list(resultadoRSLP.iloc[:].values),\\\n",
    "            \"SNOW\":list(resultadoSNOW.iloc[:].values),\\\n",
    "            \"CHAVESOUNDEX\":list(resultadoSOUND.iloc[:].values),\\\n",
    "            \"BUSCABR_SEM_VOGAL\":list(resultadoBSBRV.iloc[:].values),\\\n",
    "            \"BUSCABR\":list(resultadoBSBRP.iloc[:].values),\\\n",
    "            \"METAPHONEBR\":list(resultadoMPBR.iloc[:].values),\\\n",
    "            \"ROBERTO\":list(resultadoLider.iloc[:].values)} \n",
    "    records.append(data)\n",
    "dfBusca = pd.DataFrame(records,columns=[\"BUSCA\",\"RSLP\",\"SNOW\",\"CHAVESOUNDEX\",\"BUSCABR_SEM_VOGAL\",\"BUSCABR\",\"METAPHONEBR\", \"ROBERTO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BUSCA</th>\n",
       "      <th>RSLP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>CHAVESOUNDEX</th>\n",
       "      <th>BUSCABR_SEM_VOGAL</th>\n",
       "      <th>BUSCABR</th>\n",
       "      <th>METAPHONEBR</th>\n",
       "      <th>ROBERTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABDALA</td>\n",
       "      <td>[ABDALA]</td>\n",
       "      <td>[ABDALA]</td>\n",
       "      <td>[ABDALA]</td>\n",
       "      <td>[ABDALA]</td>\n",
       "      <td>[ABDALA]</td>\n",
       "      <td>[ABDALA]</td>\n",
       "      <td>[ABDALA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABDIAS</td>\n",
       "      <td>[ABDIAS]</td>\n",
       "      <td>[ABDIAS]</td>\n",
       "      <td>[ABDIAS, ABIDIAS, AVIDES]</td>\n",
       "      <td>[ABDIAS, ABIDIAS]</td>\n",
       "      <td>[ABDIAS]</td>\n",
       "      <td>[ABDIAS, ABIDIAS]</td>\n",
       "      <td>[ABDIAS, ABIDIAS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABEILARD</td>\n",
       "      <td>[ABEILARD]</td>\n",
       "      <td>[ABEILARD]</td>\n",
       "      <td>[ABEILARD, ABELARD]</td>\n",
       "      <td>[ABEILARD, ABELARD, UBALDO]</td>\n",
       "      <td>[ABEILARD]</td>\n",
       "      <td>[ABEILARD, ABELARD]</td>\n",
       "      <td>[ABEILARD, ABELARD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABEL</td>\n",
       "      <td>[ABEL, ABELA]</td>\n",
       "      <td>[ABEL, ABELA]</td>\n",
       "      <td>[ABEL, ABELA, ABILIO]</td>\n",
       "      <td>[ABEL, ABIA, ABRAAO, ABRAO, BRAZ, EBER, EBIO, ...</td>\n",
       "      <td>[ABEL]</td>\n",
       "      <td>[ABEL, ABELA, ABILIO]</td>\n",
       "      <td>[ABEL, ABELA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABELA</td>\n",
       "      <td>[ABEL, ABELA]</td>\n",
       "      <td>[ABEL, ABELA]</td>\n",
       "      <td>[ABEL, ABELA, ABILIO]</td>\n",
       "      <td>[ABELA, ABILIO, BERIL, BORIS, BRAULIO, BYRON, ...</td>\n",
       "      <td>[ABELA]</td>\n",
       "      <td>[ABEL, ABELA, ABILIO]</td>\n",
       "      <td>[ABEL, ABELA]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BUSCA           RSLP           SNOW               CHAVESOUNDEX  \\\n",
       "0    ABDALA       [ABDALA]       [ABDALA]                   [ABDALA]   \n",
       "1    ABDIAS       [ABDIAS]       [ABDIAS]  [ABDIAS, ABIDIAS, AVIDES]   \n",
       "2  ABEILARD     [ABEILARD]     [ABEILARD]        [ABEILARD, ABELARD]   \n",
       "3      ABEL  [ABEL, ABELA]  [ABEL, ABELA]      [ABEL, ABELA, ABILIO]   \n",
       "4     ABELA  [ABEL, ABELA]  [ABEL, ABELA]      [ABEL, ABELA, ABILIO]   \n",
       "\n",
       "                                   BUSCABR_SEM_VOGAL     BUSCABR  \\\n",
       "0                                           [ABDALA]    [ABDALA]   \n",
       "1                                  [ABDIAS, ABIDIAS]    [ABDIAS]   \n",
       "2                        [ABEILARD, ABELARD, UBALDO]  [ABEILARD]   \n",
       "3  [ABEL, ABIA, ABRAAO, ABRAO, BRAZ, EBER, EBIO, ...      [ABEL]   \n",
       "4  [ABELA, ABILIO, BERIL, BORIS, BRAULIO, BYRON, ...     [ABELA]   \n",
       "\n",
       "             METAPHONEBR              ROBERTO  \n",
       "0               [ABDALA]             [ABDALA]  \n",
       "1      [ABDIAS, ABIDIAS]    [ABDIAS, ABIDIAS]  \n",
       "2    [ABEILARD, ABELARD]  [ABEILARD, ABELARD]  \n",
       "3  [ABEL, ABELA, ABILIO]        [ABEL, ABELA]  \n",
       "4  [ABEL, ABELA, ABILIO]        [ABEL, ABELA]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBusca.to_csv(path_or_buf='resultado_buscas2.csv',encoding='utf-8')\n",
    "dfBusca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento dos Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Função para realização das busca de uma palavra utilizando todas as chaves fonéticas\n",
    "\n",
    "def busca_nome(palavra):     \n",
    "    \n",
    "    chaveFonetica = chavemeta.chaveMetaphoneBR(palavra)\n",
    "    resultadoMPBR =nomes_com_chave[nomes_com_chave['METAPHONEBR']==chaveFonetica].NOME\n",
    "    \n",
    "    chaveFonetica =  chaveRoberto.chavefonetica(palavra)\n",
    "    resultadoRoberto = nomes_com_chave[nomes_com_chave['ROBERTO']==chaveFonetica.strip()].NOME  \n",
    "    \n",
    "    chaveFonetica = stemmerRSLP.stem(palavra.decode('utf-8')).upper()\n",
    "    resultadoRSLP = nomes_com_chave[nomes_com_chave['RSLP']==chaveFonetica].NOME  \n",
    "    \n",
    "    chaveFonetica = chavesoundex.soundex(palavra.decode('utf-8'))\n",
    "    resultadoSOUND = nomes_com_chave[nomes_com_chave['CHAVESOUNDEX']==chaveFonetica].NOME  \n",
    "    \n",
    "    chaveFonetica = chavebr.chaveBR(palavra,False)\n",
    "    resultadoBSBRP = nomes_com_chave[nomes_com_chave['BUSCABR']==chaveFonetica].NOME  \n",
    "    \n",
    "    chaveFonetica = chavebr.chaveBR(palavra,True)\n",
    "    resultadoBSBRV = nomes_com_chave[nomes_com_chave['BUSCABR_SEM_VOGAL']==chaveFonetica].NOME  \n",
    "    \n",
    "    chaveFonetica = stemmersnow.stem(palavra.decode('utf-8')).upper()\n",
    "    resultadoSNOW = nomes_com_chave[nomes_com_chave['SNOW']==chaveFonetica].NOME      \n",
    "\n",
    "    data = {\"RSLP\":{\"NOMESENCONTRADOS\":list(resultadoRSLP.iloc[:].values)},\\\n",
    "            \"SNOW\":{\"NOMESENCONTRADOS\":list(resultadoSNOW.iloc[:].values)},\\\n",
    "            \"CHAVESOUNDEX\":{\"NOMESENCONTRADOS\":list(resultadoSOUND.iloc[:].values)},\\\n",
    "            \"BUSCABR_SEM_VOGAL\":{\"NOMESENCONTRADOS\":list(resultadoBSBRV.iloc[:].values)},\\\n",
    "            \"BUSCABR\":{\"NOMESENCONTRADOS\":list(resultadoBSBRP.iloc[:].values)},\\\n",
    "            \"METAPHONEBR\":{\"NOMESENCONTRADOS\":list(resultadoMPBR.iloc[:].values)},\\\n",
    "            \"ROBERTO\":{\"NOMESENCONTRADOS\":list(resultadoRoberto.iloc[:].values)}\n",
    "            } \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculo das métricas\n",
    "\n",
    "def contar_ocorrencias(busca,esperado,nomesEncontrados):\n",
    "    acertos = 0\n",
    "    acertosl = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    fpl= 0\n",
    "    fnl = 0\n",
    "    nomesEncontradosL = []\n",
    "    \n",
    "    for index,item in enumerate(nomesEncontrados):\n",
    "        if nltk.edit_distance(item, busca) <=2 :\n",
    "            nomesEncontradosL.append(item)\n",
    "        \n",
    "    # Calcular Falso negativos\n",
    "    for index,item in enumerate(esperado):\n",
    "        if item in nomesEncontrados:\n",
    "            acertos += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "           \n",
    "    \n",
    "    # Calcular Falso negativos levestein\n",
    "    for index,item in enumerate(esperado):\n",
    "        if item in nomesEncontradosL:\n",
    "            acertosl += 1\n",
    "        else:\n",
    "            fnl += 1\n",
    "               \n",
    "    \n",
    "    #calcular falsos positivos\n",
    "    for index,item in enumerate(nomesEncontrados):\n",
    "        if item not in esperado:\n",
    "            fp += 1\n",
    "                       \n",
    "    #calcular falsos positivos levestein\n",
    "    for index,item in enumerate(nomesEncontradosL):\n",
    "        if item not in esperado:\n",
    "            fpl += 1\n",
    "           \n",
    "    #print('Esperado: ', esperado , ' Encontrados: ' , nomesEncontrados , ' Acertos: ' , str(acertos), 'FP',fp,'FN',fn )     \n",
    "    return acertos,acertosl,fp,fn,fpl,fnl\n",
    "\n",
    "def calculaF1(acertos,fp,fn):\n",
    "\n",
    "    try:\n",
    "        precision = float(acertos)/(acertos+fp)\n",
    "        recall = float(acertos)/(acertos+fn)\n",
    "        return float(2*(precision*recall)/(precision+recall))\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def calcula(nroarq):\n",
    "    records = []\n",
    "\n",
    "\n",
    "    sumacertos = [0,0,0,0,0,0,0]\n",
    "    sumacertosl = [0,0,0,0,0,0,0]\n",
    "    sumfp = [0,0,0,0,0,0,0]\n",
    "    sumfn = [0,0,0,0,0,0,0]\n",
    "    sumfpl = [0,0,0,0,0,0,0]\n",
    "    sumfnl = [0,0,0,0,0,0,0]\n",
    "\n",
    "    for index,row in buscasdf.iterrows():\n",
    "        busca = row[0]\n",
    "        data = busca_nome(busca)\n",
    "        resultado = row[1].split(',')\n",
    "\n",
    "        #Dados de cada algoritmo\n",
    "        acertos = [0,0,0,0,0,0,0]\n",
    "        acertosl = [0,0,0,0,0,0,0]\n",
    "        fp = [0,0,0,0,0,0,0]\n",
    "        fn = [0,0,0,0,0,0,0]\n",
    "        fpl = [0,0,0,0,0,0,0]\n",
    "        fnl = [0,0,0,0,0,0,0] \n",
    "        f1 = [0,0,0,0,0,0,0] \n",
    "        #RSLP\n",
    "        nomesEncontrados = data['RSLP']['NOMESENCONTRADOS']\n",
    "        acertos[0],acertosl[0],fp[0],fn[0],fpl[0],fnl[0] = contar_ocorrencias(busca,resultado,nomesEncontrados)\n",
    "        sumacertos[0] += acertos[0]\n",
    "        sumacertosl[0] += acertosl[0]\n",
    "        sumfp[0] += fp[0]\n",
    "        sumfn[0] += fn[0]\n",
    "        sumfpl[0] += fpl[0]\n",
    "        sumfnl[0] += fnl[0]\n",
    "\n",
    "        f1[0] = calculaF1(acertos[0],fp[0],fn[0])\n",
    "\n",
    "        #SNOWBALL\n",
    "        nomesEncontrados = data['SNOW']['NOMESENCONTRADOS']\n",
    "        acertos[1],acertosl[1],fp[1],fn[1],fpl[1],fnl[1] = contar_ocorrencias(busca,resultado,nomesEncontrados)\n",
    "        sumacertos[1] += acertos[1]\n",
    "        sumacertosl[1] += acertosl[1]\n",
    "        sumfp[1] += fp[1]\n",
    "        sumfn[1] += fn[1]\n",
    "        sumfpl[1] += fpl[1]\n",
    "        sumfnl[1] += fnl[1]\n",
    "        f1[1] = calculaF1(acertos[1],fp[1],fn[1])\n",
    "\n",
    "        #SOUNDEX\n",
    "        nomesEncontrados = data['CHAVESOUNDEX']['NOMESENCONTRADOS']\n",
    "        acertos[2],acertosl[2],fp[2],fn[2],fpl[2],fnl[2] = contar_ocorrencias(busca,resultado,nomesEncontrados)\n",
    "        sumacertos[2] += acertos[2]\n",
    "        sumacertosl[2] += acertosl[2]\n",
    "        sumfp[2] += fp[2]\n",
    "        sumfn[2] += fn[2]\n",
    "        sumfpl[2] += fpl[2]\n",
    "        sumfnl[2] += fnl[2]\n",
    "        f1[2] = calculaF1(acertos[2],fp[2],fn[2])\n",
    "\n",
    "        #BUSCABR_SEM_VOGAL\n",
    "        nomesEncontrados = data['BUSCABR_SEM_VOGAL']['NOMESENCONTRADOS']\n",
    "        acertos[3],acertosl[3],fp[3],fn[3],fpl[3],fnl[3] = contar_ocorrencias(busca,resultado,nomesEncontrados)\n",
    "        sumacertos[3] += acertos[3]\n",
    "        sumacertosl[3] += acertosl[3]\n",
    "        sumfp[3] += fp[3]\n",
    "        sumfn[3] += fn[3]\n",
    "        sumfpl[3] += fpl[3]\n",
    "        sumfnl[3] += fnl[3]\n",
    "        f1[3] = calculaF1(acertos[3],fp[3],fn[3])\n",
    "\n",
    "        #BUSCABR\n",
    "        nomesEncontrados = data['BUSCABR']['NOMESENCONTRADOS']\n",
    "        acertos[4],acertosl[4],fp[4],fn[4],fpl[4],fnl[4] = contar_ocorrencias(busca,resultado,nomesEncontrados)\n",
    "        sumacertos[4] += acertos[4]\n",
    "        sumacertosl[4] += acertosl[4]\n",
    "        sumfp[4] += fp[4]\n",
    "        sumfn[4] += fn[4]\n",
    "        sumfpl[4] += fpl[4]\n",
    "        sumfnl[4] += fnl[4]\n",
    "        f1[4] = calculaF1(acertos[4],fp[4],fn[4])\n",
    "\n",
    "        #METAPHONE\n",
    "        nomesEncontrados = data['METAPHONEBR']['NOMESENCONTRADOS']\n",
    "        acertos[5],acertosl[5],fp[5],fn[5],fpl[5],fnl[5] = contar_ocorrencias(busca,resultado,nomesEncontrados)\n",
    "        sumacertos[5] += acertos[5]\n",
    "        sumacertosl[5] += acertosl[5]\n",
    "        sumfp[5] += fp[5]\n",
    "        sumfn[5] += fn[5]\n",
    "        sumfpl[5] += fpl[5]\n",
    "        sumfnl[5] += fnl[5]\n",
    "        f1[5] = calculaF1(acertos[5],fp[5],fn[5])\n",
    "\n",
    "        #ROBERTO\n",
    "        nomesEncontrados = data['ROBERTO']['NOMESENCONTRADOS']\n",
    "        acertos[6],acertosl[6],fp[6],fn[6],fpl[6],fnl[6] = contar_ocorrencias(busca,resultado,nomesEncontrados)\n",
    "        sumacertos[6] += acertos[6]\n",
    "        sumacertosl[6] += acertosl[6]\n",
    "        sumfp[6] += fp[6]\n",
    "        sumfn[6] += fn[6]\n",
    "        sumfpl[6] += fpl[6]\n",
    "        sumfnl[6] += fnl[6]\n",
    "        f1[6] = calculaF1(acertos[6],fp[6],fn[6])\n",
    "\n",
    "\n",
    "        linha ={\"BUSCA\":busca,\"Resultado Esperado\": row['Retorno Esperado'],\\\n",
    "                'RSLP': data['RSLP']['NOMESENCONTRADOS'],\"ACRSLP\": str( acertos[0]),\"FPRSLP\": str(fp[0]),\"FNRSLP\":str(fn[0]),\"F1RSLP\":str(f1[0]),\\\n",
    "                'SNOW': data['SNOW']['NOMESENCONTRADOS'],\"ACSNOW\": str( acertos[1]),\"FPSNOW\": str(fp[1]),\"FNSNOW\":str(fn[1]),\"F1SNOW\":str(f1[1]),\\\n",
    "                'CHAVESOUNDEX': data['CHAVESOUNDEX']['NOMESENCONTRADOS'],\"ACCHAVESOUNDEX\": str( acertos[2]),\"FPCHAVESOUNDEX\": str(fp[2]),\"FNCHAVESOUNDEX\":str(fn[2]),\"F1CHAVESOUNDEX\":str(f1[2]),\\\n",
    "                'BUSCABR_SEM_VOGAL': data['BUSCABR_SEM_VOGAL']['NOMESENCONTRADOS'],\"ACBUSCABRSV\": str( acertos[3]),\"FPBUSCABRSV\": str(fp[3]),\"FNBUSCABRSV\":str(fn[3]),\"F1BUSCABRSV\":str(f1[3]),\\\n",
    "                'BUSCABR': data['BUSCABR']['NOMESENCONTRADOS'],\"ACBUSCABR\": str( acertos[4]),\"FPBUSCABR\": str(fp[4]),\"FNBUSCABR\":str(fn[4]),\"F1BUSCABR\":str(f1[4]),\\\n",
    "                'METAPHONEBR': data['METAPHONEBR']['NOMESENCONTRADOS'],\"ACMETAPHONEBR\": str(acertos[5]),\"FPMETAPHONEBR\": str(fp[5]),\"FNMETAPHONEBR\":str(fn[5]),\"F1METAPHONEBR\":str(f1[5]),\\\n",
    "                'ROBERTO': data['ROBERTO']['NOMESENCONTRADOS'],\"ACROBERTO\": str( acertos[6]),\"FPROBERTO\": str(fp[6]),\"FNROBERTO\":str(fn[6]),\"F1ROBERTO\":str(f1[6])  }\n",
    "\n",
    "        records.append(linha)\n",
    "\n",
    "\n",
    "    #Gerar linha com sumarizacao    \n",
    "    linha ={\"BUSCA\":\"\",\"Resultado Esperado\": \"\",\\\n",
    "            'RSLP': \"\",\"ACRSLP\": str( sumacertos[0]),\"FPRSLP\": str(sumfp[0]),\"FNRSLP\":str(sumfn[0]),\\\n",
    "            'SNOW': \"\",\"ACSNOW\": str( sumacertos[1]),\"FPSNOW\": str(sumfp[1]),\"FNSNOW\":str(sumfn[1]),\\\n",
    "            'CHAVESOUNDEX': \"\",\"ACCHAVESOUNDEX\": str( sumacertos[2]),\"FPCHAVESOUNDEX\": str(sumfp[2]),\"FNCHAVESOUNDEX\":str(sumfn[2]),\\\n",
    "            'BUSCABR_SEM_VOGAL':\"\",\"ACBUSCABRSV\": str( sumacertos[3]),\"FPBUSCABRSV\": str(sumfp[3]),\"FNBUSCABRSV\":str(sumfn[3]),\\\n",
    "            'BUSCABR': \"\",\"ACBUSCABR\": str( sumacertos[4]),\"FPBUSCABR\": str(sumfp[4]),\"FNBUSCABR\":str(sumfn[4]),\\\n",
    "            'METAPHONEBR': \"\",\"ACMETAPHONEBR\": str( sumacertos[5]),\"FPMETAPHONEBR\": str(sumfp[5]),\"FNMETAPHONEBR\":str(sumfn[5]),\\\n",
    "            'ROBERTO': \"\",\"ACROBERTO\": str( sumacertos[6]),\"FPROBERTO\": str(sumfp[6]),\"FNROBERTO\":str(sumfn[6]) }\n",
    "\n",
    "    records.append(linha)\n",
    "\n",
    "\n",
    "    #Gerar metrica F1\n",
    "\n",
    "    # Os nomes das colunas devem seguir o mesmo padrao por causa da serialização em arquivo do pandas\n",
    "    linha = {\"BUSCA\":\"Algoritmo\",\"Resultado Esperado\":\"Precision\",\"RSLP\":\"Recall\",\"ACRSLP\":\"F1\"}\n",
    "    records.append(linha)\n",
    "\n",
    "    algoritmos =[\"RSLP\",\"SNOWBALL\",\"SOUNDEX\",\"BUSCABR_SEM_VOGAL\",\"BUSCABR\",\"METAPHONEBR\",\"ROBERTO\"]\n",
    "\n",
    "    for x in range(0, 7): \n",
    "\n",
    "        precision = float(sumacertos[x])/(sumacertos[x]+sumfp[x])\n",
    "        recall = float(sumacertos[x])/(sumacertos[x]+sumfn[x])\n",
    "        f1 = float(2*(precision*recall)/(precision+recall))\n",
    "\n",
    "        precisionl = float(sumacertosl[x])/(sumacertosl[x]+sumfpl[x])\n",
    "        recalll = float(sumacertosl[x])/(sumacertosl[x]+sumfnl[x])\n",
    "        f1l = float(2*(precisionl*recalll)/(precisionl+recalll))   \n",
    "\n",
    "        linha = {\"BUSCA\":algoritmos[x],\"Resultado Esperado\":'{percent:.2%}'.format(percent=precision).replace('.',','),\n",
    "                 \"RSLP\":'{percent:.2%}'.format(percent=recall).replace('.',','),\"ACRSLP\":'{percent:.2%}'.format(percent=f1).replace('.',',')}\n",
    "\n",
    "        records.append(linha)\n",
    "\n",
    "        linha = {\"BUSCA\":algoritmos[x] + \" Levenshtein\",\"Resultado Esperado\":'{percent:.2%}'.format(percent=precisionl).replace('.',','),\n",
    "                 \"RSLP\":'{percent:.2%}'.format(percent=recalll).replace('.',','),\"ACRSLP\":'{percent:.2%}'.format(percent=f1l).replace('.',',')}\n",
    "\n",
    "        records.append(linha)    \n",
    "\n",
    "    df = pd.DataFrame(records,columns=[\"BUSCA\",\"Resultado Esperado\",\\\n",
    "                                       \"RSLP\",\"ACRSLP\",\"FPRSLP\",\"FNRSLP\",\"F1RSLP\",\\\n",
    "                                       \"SNOW\",\"ACSNOW\",\"FPSNOW\",\"FNSNOW\",\"F1SNOW\",\n",
    "                                       \"CHAVESOUNDEX\",\"ACCHAVESOUNDEX\",\"FPCHAVESOUNDEX\",\"FNCHAVESOUNDEX\",\"F1CHAVESOUNDEX\",\n",
    "                                       \"BUSCABR_SEM_VOGAL\",\"ACBUSCABRSV\",\"FPBUSCABRSV\",\"FNBUSCABRSV\",\"F1BUSCABRSV\",\n",
    "                                       \"BUSCABR\",\"ACBUSCABR\",\"FPBUSCABR\",\"FNBUSCABR\",\"F1BUSCABR\",\n",
    "                                       \"METAPHONEBR\",\"ACMETAPHONEBR\",\"FPMETAPHONEBR\",\"FNMETAPHONEBR\",\"F1METAPHONEBR\",\n",
    "                                       \"ROBERTO\",\"ACROBERTO\",\"FPROBERTO\",\"FNROBERTO\",\"F1ROBERTO\"])  \n",
    "\n",
    "\n",
    "\n",
    "    #Gravando o resultado em CSV\n",
    "    nomearq = 'testes_automaticos_' + str(nroarq)+ '.csv'\n",
    "    df.to_csv(path_or_buf=nomearq,index=False,encoding='utf-8',sep=\";\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo buscas_214.csv\n"
     ]
    }
   ],
   "source": [
    "qtds = [214]\n",
    "for nroarq in qtds:\n",
    "    #Carga do arquivo que contem os nomes para busca e os resultados esperados para cada nome de acordo com a base utilizada\n",
    "    nome_arq = 'buscas_'+str(nroarq)+'.csv'\n",
    "    print('Lendo ' + nome_arq)\n",
    "    buscasdf = pd.read_csv(filepath_or_buffer=nome_arq, sep=';')\n",
    "    calcula(nroarq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
